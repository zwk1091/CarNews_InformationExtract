标题：借鉴接种疫苗原理CSIRO研发新技术可让自动驾驶神经网络对黑客攻击免疫
内容：盖世汽车讯据外媒报道，澳大利亚国家科学研究局（CSIRO）研发出一种编程技术，该技术的工作原理与疾病预防疫苗接种类似，能够保护机器学习系统免受恶意的网络攻击。现代社会中，机器学习系统（或称神经网络）正变得越来越流行，而且被广泛应用于交通管理、医疗诊断和农业等各个领域，此外，它们还是自动驾驶汽车的关键部件。从最初的训练阶段开始，机器学习系统会在给定的任务中重复运行成千上万次，然后，得出的算法才具备学习的能力，被添加至其计算机指令系统，并据此采取行动，无需进一步的人工操作。尽管机器学习系统与其他由计算机驱动的机制一样，效率很高，但是，此类系统仍然容易受到黑客攻击。黑客攻击的主要方式就是引入“噪音”（额外的数据点，以干扰和扭曲输入信号），从而使外部元素被错误地分类。此类黑客攻击术语称为将“对抗性实例”引入该系统，通过添加噪音，机器学习算法将会被误导，无法正确对熊猫和长臂猿的图像进行分类。此外，随着自动驾驶汽车的兴起，一旦自动驾驶汽车的机器学习系统被入侵，该系统可能会将停车标志误分类为绿色交通信号灯。因此，让机器学习系统能够抵御黑客攻击一直是一个活跃的研究议题。而最新抵御方法是由RichardNock从公共卫生方面汲取的经验。在医学上，接种疫苗建立在这样一个理念上，即让身体的免疫系统暴露在虚弱或已经死亡的病原体（例如，导致流感或脊髓灰质炎的病原体）环境中，可以促进免疫系统产生特定的抗体，随后，免疫系统会“记住”病原体，下次遇到时，免疫系统会认出病原体并全力将其立马清除。Nock和同事也采取了相同的方法。Nock解释表示：“我们的新方法使用了类似于疫苗接种的过程来预防黑客攻击。我们先打造一个较弱的黑客攻击，例如小幅度地修改或扭曲图像，以创造一个更加复杂的训练数据集。当该算法的训练数据暴露在小幅度的失真或修改环境中，得到的模型就会更加强大，对此类黑客攻击免疫。”虽然该方法还处于研究早期阶段，还未在现实世界中进行测试，以对抗恶意黑客入侵，但是将会是一个非常有前景的方法。
