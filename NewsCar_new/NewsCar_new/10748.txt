标题：「征服复杂地形后的新考验」无人驾驶的判断难题
内容：近年来，越来越多的地区开启了无人驾驶测试，但这同时也意味着风险与日俱增。和此前的无人驾驶事故不同，新领域的风险来自AI落后的判断逻辑，而非复杂的地形环境。无人驾驶技术遭遇瓶颈在解决出行问题后，技术专家们正在冲击‘无人驾驶技术的判断机制’这个技术难关。Uber首席科学家拉克尔·乌尔塔森（RaquelUrtasun）本周一表示：公司相信无人驾驶汽车大规模应用还要等很长一段时间，不过新技术的确能拯救生命。难住优步的技术人员的，是为无人驾驶司机配备的AI判断功能。不久前，腾讯科恩实验室发现了特斯拉ModelS轿车的自动驾驶系统（版本2018.6.1）存在着三大漏洞，其中包括了可以通过外部激活车辆的雨刷系统、通过在道路上设置一些特定的标记可以欺骗ModelS的自动驾驶系统使其驶入错误车道，并且通过无线游戏手柄就可以操控ModelS的转向系统，从而控制车辆，使其成为“僵尸汽车”。这就是典型的判断机制问题。以城中村为例，理论上无人驾驶汽车进入城中村，并不会像人类司机一样迷惘：对无人驾驶司机而言，城中村的复杂程度，未必比城市内部的风景区或大量单行路的政府办公区更复杂。然而事实上，无人驾驶汽车很难在这类地区安全前进，理由就是判断机制问题。有专家表示：无人驾驶商业落地的关键在于提升系统的安全边界，覆盖各类复杂场景和不断提升系统的稳定性和可靠性，从而提升判断水平。提升思考能力让无人驾驶更聪明无人驾驶的反应速度会因为卫星的增加而不断提升，但不会因为地区通信质量的降低或地形变的更加复杂而效率降低，这是人类驾驶员才有的问题。相应的，适用于无人驾驶软件的AI判断机制，却远没达到和人类近似的水平。比如很著名的usbr无人驾驶事件。该事件发生时，无人驾驶汽车在没有障碍物的情况下直接就对着受害者撞了过去。原因很简单：无人驾驶司机并未把受害者识别为交通的一部分。另一起谷歌事故则更明显地反映出了这个问题：在这起事故中，无人驾驶司机并无任何责任，它唯一的问题是没有看到对方撞过来的时候及时躲开...但‘在任何情况下都可以自主选择躲避’本身就是属于人类司机判断机制的一部分。特斯拉新暴露的漏洞，则进一步说明了：如果判断机制不够完善，无人驾驶技术能造成多大的危害。所以，升级无人驾驶技术的关键，不在其他，就在提升判断水平上。目前，无人驾驶厂商们也已经认知到了这个关键点。2018年的报告中，首屈一指的Waymo需要人为干预的频次已经降低到0.18次/千英里的水平。在谷歌雄厚财力的支持下，相信他们彻底改良判断机制的时间，离我们已经不远了。
